{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from model import UniSkip\n",
    "from config import *\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DataLoader(\"./data/dummy_corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = UniSkip()\n",
    "if USE_CUDA:\n",
    "    mod.cuda(CUDA_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(params=mod.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trail = []\n",
    "last_best_loss = None\n",
    "current_time = datetime.utcnow()\n",
    "\n",
    "def debug(i, loss, prev, nex, prev_pred, next_pred):\n",
    "    global loss_trail\n",
    "    global last_best_loss\n",
    "    global current_time\n",
    "\n",
    "    this_loss = loss.data[0]\n",
    "    loss_trail.append(this_loss)\n",
    "    loss_trail = loss_trail[-20:]\n",
    "    new_current_time = datetime.utcnow()\n",
    "    time_elapsed = str(new_current_time - current_time)\n",
    "    current_time = new_current_time\n",
    "    print(\"Iteration {}: time = {} last_best_loss = {}, this_loss = {}\".format(\n",
    "              i, time_elapsed, last_best_loss, this_loss))\n",
    "    \n",
    "    print(\"prev = {}\\nnext = {}\\npred_prev = {}\\npred_next = {}\".format(\n",
    "        d.convert_indices_to_sentences(prev),\n",
    "        d.convert_indices_to_sentences(nex),\n",
    "        d.convert_indices_to_sentences(prev_pred),\n",
    "        d.convert_indices_to_sentences(next_pred),\n",
    "    ))\n",
    "    \n",
    "    try:\n",
    "        trail_loss = sum(loss_trail)/len(loss_trail)\n",
    "        if last_best_loss is None or last_best_loss > trail_loss:\n",
    "            print(\"Loss improved from {} to {}\".format(last_best_loss, trail_loss))\n",
    "            \n",
    "            save_loc = \"./saved_models/skip-best\".format(lr, VOCAB_SIZE)\n",
    "            print(\"saving model at {}\".format(save_loc))\n",
    "            torch.save(mod.state_dict(), save_loc)\n",
    "            \n",
    "            last_best_loss = trail_loss\n",
    "    except Exception as e:\n",
    "       print(\"Couldn't save model because {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "# a million iterations\n",
    "for i in range(0, 1000000):\n",
    "    sentences, lengths = d.fetch_batch(32 * 8)\n",
    "\n",
    "    loss, prev, nex, prev_pred, next_pred  = mod(sentences, lengths)\n",
    "    \n",
    "\n",
    "    if i % 10 == 0:\n",
    "        debug(i, loss, prev, nex, prev_pred, next_pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
